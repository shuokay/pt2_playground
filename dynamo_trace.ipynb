{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3040a9c1-1af8-4115-95cd-8c67804a8ed1",
   "metadata": {},
   "source": [
    "# torch._dynamo.export 结论（2023-12-07）\n",
    "1. 支持静态 flag 控制\n",
    "2. 不支持 Tensor 控制，torch 建议使用 `functorch.experimental.control_flow.cond` 无法调通，同样报错不支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e750aba-9c18-4ac7-9e3c-433ce7fa1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75659b7a-3bf1-4e01-9467-b45b58b5156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549bc4f6-2574-4a37-b783-73f7bd8592e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        arg0: f32[s0], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # File: /tmp/ipykernel_194925/4153613159.py:2, code: if x.shape[0] > 2:\n",
      "        size = arg0.size()\n",
      "        getitem = size[0];  size = None\n",
      "        gt = getitem > 2;  getitem = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_194925/4153613159.py:4, code: return torch.sigmoid(x)\n",
      "        sigmoid = torch.sigmoid(arg0);  arg0 = None\n",
      "        return pytree.tree_unflatten([sigmoid], self._out_spec)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, x):\\n        arg0: f32[s0], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\\n        # File: /tmp/ipykernel_194925/4153613159.py:2, code: if x.shape[0] > 2:\\n        size = arg0.size()\\n        getitem = size[0];  size = None\\n        gt = getitem > 2;  getitem = None\\n        \\n        # File: /tmp/ipykernel_194925/4153613159.py:4, code: return torch.sigmoid(x)\\n        sigmoid = torch.sigmoid(arg0);  arg0 = None\\n        return pytree.tree_unflatten([sigmoid], self._out_spec)\\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn_flag(x):\n",
    "    if x.shape[0] > 2:\n",
    "        return torch.relu(x)\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "x = torch.randn(2)\n",
    "out = torch._dynamo.export(fn_flag)(x)\n",
    "out.graph_module.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82107a94-5264-405a-816c-787e98a4e059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "         global '' GRAD_MODE\n",
       "         {\n",
       "             'guard_types': ['GRAD_MODE'],\n",
       "             'code': ['___is_grad_enabled()'],\n",
       "             'obj_weakref': None\n",
       "             'guarded_class': None\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         local \"L['x']\" TENSOR_MATCH\n",
       "         {\n",
       "             'guard_types': ['TYPE_MATCH', 'TENSOR_MATCH'],\n",
       "             'code': [\"___check_type_id(L['x'], 92004160)\", \"str(L['x'].dtype) == 'torch.float32'\", \"str(L['x'].device) == 'cpu'\", \"L['x'].requires_grad == False\", \"L['x'].ndimension() == 1\", \"hasattr(L['x'], '_dynamo_dynamic_indices') == False\"],\n",
       "             'obj_weakref': <weakref at 0x7fd58f23ab80; to 'Tensor' at 0x7fd5aa2bc270>\n",
       "             'guarded_class': <weakref at 0x7fd5abdef950; to 'torch._C._TensorMeta' at 0x57bdf40 (Tensor)>\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         global \"G['torch']\" FUNCTION_MATCH\n",
       "         {\n",
       "             'guard_types': None,\n",
       "             'code': None,\n",
       "             'obj_weakref': None\n",
       "             'guarded_class': None\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         global '' DETERMINISTIC_ALGORITHMS\n",
       "         {\n",
       "             'guard_types': ['DETERMINISTIC_ALGORITHMS'],\n",
       "             'code': ['not ___are_deterministic_algorithms_enabled()'],\n",
       "             'obj_weakref': None\n",
       "             'guarded_class': None\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         global '' TORCH_FUNCTION_STATE\n",
       "         {\n",
       "             'guard_types': ['TORCH_FUNCTION_STATE'],\n",
       "             'code': ['___is_torch_function_enabled()'],\n",
       "             'obj_weakref': None\n",
       "             'guarded_class': None\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         local \"L['x']\" TYPE_MATCH\n",
       "         {\n",
       "             'guard_types': ['TYPE_MATCH'],\n",
       "             'code': [\"___check_type_id(L['x'], 92004160)\"],\n",
       "             'obj_weakref': <weakref at 0x7fd58f23ab80; to 'Tensor' at 0x7fd5aa2bc270>\n",
       "             'guarded_class': <weakref at 0x7fd5abdef950; to 'torch._C._TensorMeta' at 0x57bdf40 (Tensor)>\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         global '' DEFAULT_DEVICE\n",
       "         {\n",
       "             'guard_types': ['DEFAULT_DEVICE'],\n",
       "             'code': ['utils_device.CURRENT_DEVICE == None'],\n",
       "             'obj_weakref': None\n",
       "             'guarded_class': None\n",
       "         }\n",
       "         ,\n",
       " \n",
       "         shape_env '' SHAPE_ENV\n",
       "         {\n",
       "             'guard_types': ['SHAPE_ENV', 'SHAPE_ENV', 'SHAPE_ENV', 'SHAPE_ENV'],\n",
       "             'code': [\"L['x'].stride()[0] == 1\", \"L['x'].storage_offset() == 0\", \"L['x'].size()[0] <= 2\", \"2 <= L['x'].size()[0]\"],\n",
       "             'obj_weakref': None\n",
       "             'guarded_class': None\n",
       "         }\n",
       "         ]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(out.guards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437eaada-a29c-4084-a3f6-993981d97942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        arg0: f32[s0], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # File: /tmp/ipykernel_194925/2675718805.py:10, code: return torch.relu(x)\n",
      "        relu = torch.relu(arg0);  arg0 = None\n",
      "        return pytree.tree_unflatten([relu], self._out_spec)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, x):\\n        arg0: f32[s0], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\\n        # File: /tmp/ipykernel_194925/2675718805.py:10, code: return torch.relu(x)\\n        relu = torch.relu(arg0);  arg0 = None\\n        return pytree.tree_unflatten([relu], self._out_spec)\\n        '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不支持 Tensor 作为判断条件，会报错\n",
    "# 其它 python 类型数据不会报错\n",
    "flag = (torch.randn(1)[0] > 0.5).item()\n",
    "\n",
    "# import numpy as np\n",
    "# flag = np.random.uniform(size=(1,))[0] > 0.5\n",
    "\n",
    "def fn_flag(x):\n",
    "    if flag:\n",
    "        return torch.relu(x)\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "x = torch.randn(2)\n",
    "out = torch._dynamo.export(fn_flag)(x)\n",
    "out.graph_module.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ce02181-b861-4afa-99e5-a70ad53e0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_data_dependent_control_flow(x):\n",
    "    if x.sum() > 0:\n",
    "        return torch.relu(x)\n",
    "    else:\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2141567-37f9-4977-a0cb-f0ad878196bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn_data_dependent_control_flow():\n",
    "    a = torch.randn(10)\n",
    "    out = torch._dynamo.export(fn_data_dependent_control_flow)(a)\n",
    "    guards = out.guards\n",
    "    gm = out.graph_module\n",
    "    print(gm)\n",
    "    for guard in guards:\n",
    "        print(guard)\n",
    "\n",
    "\n",
    "test_fn_data_dependent_control_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4447b0-f9cf-47c2-8875-b549331aa218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试过 lambda function，x.sum(), x.shape 等判断条件，都不支持\n",
    "def true_fn(x):\n",
    "    return torch.relu(x)\n",
    "\n",
    "\n",
    "def false_fn(x):\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def fn_data_dependent_control_flow(x):\n",
    "    return torch._higher_order_ops.cond(x.shape[0] > 0, true_fn, false_fn, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23f3a9-29d4-4a18-8715-16ac5bb2dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn_data_dependent_control_flow():\n",
    "    a = torch.randn(10)\n",
    "    out = torch._dynamo.export(fn_data_dependent_control_flow)(a)\n",
    "    guards = out.guards\n",
    "    gm = out.graph_module\n",
    "    print(gm)\n",
    "    for guard in guards:\n",
    "        print(guard)\n",
    "\n",
    "\n",
    "test_fn_data_dependent_control_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c74118a-d184-42a1-95fa-c8ca291cbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 3, 3, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "x  = torch.randn(1, 1, 10, 10)\n",
    "net = Net()\n",
    "y = net(x)\n",
    "exported = torch._dynamo.export(net, aten_graph=True, pre_dispatch=True)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3613c8db-d992-4be2-a82d-8c61f3febf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        arg0: f32[1, 1, s0, s0], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # File: /tmp/ipykernel_22132/4130250000.py:11, code: x = self.conv(x)\n",
      "        _param_constant0 = self._param_constant0\n",
      "        _param_constant1 = self._param_constant1\n",
      "        conv2d_default: f32[1, 3, (s0//3), (s0//3)] = torch.ops.aten.conv2d.default(arg0, _param_constant0, _param_constant1, [3, 3]);  arg0 = _param_constant0 = _param_constant1 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_22132/4130250000.py:12, code: x = self.relu(x)\n",
      "        relu_default: f32[1, 3, (s0//3), (s0//3)] = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_22132/4130250000.py:13, code: x = torch.sigmoid(x)\n",
      "        sigmoid_default: f32[1, 3, (s0//3), (s0//3)] = torch.ops.aten.sigmoid.default(relu_default);  relu_default = None\n",
      "        return pytree.tree_unflatten([sigmoid_default], self._out_spec)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, x):\\n        arg0: f32[1, 1, s0, s0], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\\n        # File: /tmp/ipykernel_22132/4130250000.py:11, code: x = self.conv(x)\\n        _param_constant0 = self._param_constant0\\n        _param_constant1 = self._param_constant1\\n        conv2d_default: f32[1, 3, (s0//3), (s0//3)] = torch.ops.aten.conv2d.default(arg0, _param_constant0, _param_constant1, [3, 3]);  arg0 = _param_constant0 = _param_constant1 = None\\n        \\n        # File: /tmp/ipykernel_22132/4130250000.py:12, code: x = self.relu(x)\\n        relu_default: f32[1, 3, (s0//3), (s0//3)] = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\\n        \\n        # File: /tmp/ipykernel_22132/4130250000.py:13, code: x = torch.sigmoid(x)\\n        sigmoid_default: f32[1, 3, (s0//3), (s0//3)] = torch.ops.aten.sigmoid.default(relu_default);  relu_default = None\\n        return pytree.tree_unflatten([sigmoid_default], self._out_spec)\\n        '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported.graph_module.print_readable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ad7238e-7441-45ae-a92f-b5e2647fb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import horizon_plugin_pytorch as hz\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 3, 3, 3)\n",
    "        self.bn = nn.BatchNorm2d(3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a15d5cd-60d2-4f5d-a0d1-46b8b2aa683c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'graph_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m net(x)\n\u001b[1;32m      4\u001b[0m exported \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mexport(net)\n\u001b[0;32m----> 5\u001b[0m gm \u001b[38;5;241m=\u001b[39m \u001b[43mexported\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_module\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'graph_module'"
     ]
    }
   ],
   "source": [
    "x  = torch.randn(1, 1, 10, 10)\n",
    "net = Net()\n",
    "y = net(x)\n",
    "exported = torch._dynamo.export(net, aten_graph=False)(x)\n",
    "gm = exported.graph_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb91d014-fbdb-478d-96a4-a99d142101cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m2023-12-13 15:33:49,894 WARNING: [Deprecated] TODO(horizon): `activation_observer` in default_calib_8bit_fake_quant_qconfig has been changed from `percentile` to `mse` since 1.10.3.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (L__self___conv): ConvReLU2d(\n",
       "    1, 3, kernel_size=(3, 3), stride=(3, 3)\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1,         scale=tensor([1.]), zero_point=tensor([0])\n",
       "      (activation_post_process): MinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8),            quant_min=-128, quant_max=127, dtype=qint8, qscheme=torch.per_channel_symmetric, ch_axis=0,         scale=tensor([1., 1., 1.]), zero_point=tensor([0, 0, 0])\n",
       "      (activation_post_process): MinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
       "    )\n",
       "  )\n",
       "  (L__self___bn): Identity()\n",
       "  (L__self___relu): Identity()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from horizon_plugin_pytorch.quantization.qconfig import (\n",
    "    default_calib_8bit_fake_quant_qconfig,\n",
    "    default_qat_8bit_fake_quant_qconfig,\n",
    "    default_qat_8bit_weight_32bit_out_fake_quant_qconfig,\n",
    "    default_calib_8bit_weight_32bit_out_fake_quant_qconfig,\n",
    ")\n",
    "from horizon_plugin_pytorch.march import March, set_march\n",
    "set_march(\"bayes\")\n",
    "qconfig = {\"\": default_qat_8bit_fake_quant_qconfig}\n",
    "hz.quantization.prepare_qat_fx(gm, qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d639710e-ac7f-46f3-9014-e713df4bb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model = hz.quantization.prepare_qat_fx(net, qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30a6846f-6d52-4221-a469-a269331be320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yushu.gao/horizon/qat_trace/horizon_plugin_pytorch/quantization/fake_quantize.py:207: UserWarning: fast training is experimental\n",
      "  warnings.warn(\"fast training is experimental\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QTensor(\n",
       "  data = tensor([[[[0.4563, 0.0000, 0.6794],\n",
       "          [0.0000, 0.0000, 0.6592],\n",
       "          [0.0000, 0.0000, 0.5679]],\n",
       "\n",
       "         [[0.0000, 0.6186, 0.0000],\n",
       "          [0.3854, 1.0039, 0.0000],\n",
       "          [0.1825, 0.5679, 0.0000]],\n",
       "\n",
       "         [[0.5172, 1.2879, 0.2941],\n",
       "          [0.4766, 0.5983, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]]], grad_fn=<AliasBackward0>),\n",
       "  scale = tensor([0.0101]),\n",
       "  zero_point = tensor([0]),\n",
       "  dtype = qint8,\n",
       "  per_channel_axis = -1,\n",
       "  is_quantized = False\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qat_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dd27cc79-2935-4e43-8ebc-d919c308850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'None'\n",
      "---\n",
      "{'L__self___conv': (\"L['self'].conv\", <class 'torch.nn.modules.conv.Conv2d'>)}\n",
      "---\n",
      "{'L__self___conv': (\"L['self'].conv\", <class 'torch.nn.modules.conv.Conv2d'>)}\n",
      "---\n",
      "{'L__self___conv': (\"L['self'].conv\", <class 'torch.nn.modules.conv.Conv2d'>)}\n",
      "---\n",
      "{'L__self___relu': (\"L['self'].relu\",\n",
      "                    <class 'torch.nn.modules.activation.ReLU'>)}\n",
      "---\n",
      "'None'\n",
      "---\n",
      "{'L__self___custom_act': (\"L['self'].custom_act\", <class '__main__.MyAct'>),\n",
      " 'L__self___custom_act_act': (\"L['self'].custom_act.act\",\n",
      "                              <class '__main__.MyReLU'>),\n",
      " 'L__self___custom_act_act_myrelu': (\"L['self'].custom_act.act.myrelu\",\n",
      "                                     <class 'torch.nn.modules.activation.ReLU'>)}\n",
      "---\n",
      "{'L__self___custom_act': (\"L['self'].custom_act\", <class '__main__.MyAct'>),\n",
      " 'L__self___custom_act_act': (\"L['self'].custom_act.act\",\n",
      "                              <class '__main__.MyReLU'>),\n",
      " 'L__self___custom_act_act_myrelu': (\"L['self'].custom_act.act.myrelu\",\n",
      "                                     <class 'torch.nn.modules.activation.ReLU'>)}\n",
      "---\n",
      "{'L__self___custom_act': (\"L['self'].custom_act\", <class '__main__.MyAct'>)}\n",
      "---\n",
      "'None'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch._export import capture_pre_autograd_graph\n",
    "class MyAct(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act = MyReLU()\n",
    "    def forward(self, x):\n",
    "        return self.act(x) + self.act(x)\n",
    "    \n",
    "class MyReLU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.myrelu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.myrelu(x)\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 3, 3, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.custom_act = MyAct()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.custom_act(x)\n",
    "        return x\n",
    "\n",
    "x  = torch.randn(1, 1, 10, 10)\n",
    "net = Net()\n",
    "y = net(x)\n",
    "exported = capture_pre_autograd_graph(net, (x, ))\n",
    "from torch.ao.quantization.pt2e.utils import _get_node_name_to_scope\n",
    "for n in exported.graph.nodes:\n",
    "    pprint(n.meta.get(\"nn_module_stack\", \"None\"))\n",
    "    print(\"---\")\n",
    "# print(exported)\n",
    "# pprint(exported)\n",
    "# exported = torch._dynamo.export(net, aten_graph=True, pre_dispatch=True)(x)\n",
    "# from torch.ao.quantization.pt2e.utils import _get_node_name_to_scope\n",
    "# _get_node_name_to_scope(gm)\n",
    "# # print(exported.graph_module)\n",
    "\n",
    "# exported = torch._dynamo.export(net, aten_graph=False, tracing_mode=\"real\")(x)\n",
    "# from torch.ao.quantization.pt2e.utils import _get_node_name_to_scope\n",
    "# _get_node_name_to_scope(gm)\n",
    "# print(exported.graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d1adfee-432a-4472-8cb6-463c64eaadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arg0': ('', NoneType),\n",
       " 'l__self___conv': ('conv', torch.nn.modules.conv.Conv2d),\n",
       " 'l__self___bn': ('bn', torch.nn.modules.batchnorm.BatchNorm2d),\n",
       " 'l__self___relu': ('relu', torch.nn.modules.activation.ReLU),\n",
       " 'output': ('', NoneType)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.ao.quantization.pt2e.utils import _get_node_name_to_scope\n",
    "_get_node_name_to_scope(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a597b5da-8de9-4c3d-9239-a6bf473e7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = torch.fx.symbolic_trace(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c70ce38-0fa7-4927-bbf8-c59e98dc59c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('conv',\n",
       "               Conv2d(1, 3, kernel_size=(3, 3), stride=(3, 3))),\n",
       "              ('relu', ReLU())]),\n",
       " '_graph': <torch.fx.graph.Graph at 0x7faa7b0001c0>,\n",
       " '_code': '\\n\\n\\ndef forward(self, x):\\n    conv = self.conv(x);  x = None\\n    relu = self.relu(conv);  conv = None\\n    sigmoid = torch.sigmoid(relu);  relu = None\\n    return sigmoid\\n    ',\n",
       " '_tracer_cls': torch.fx._symbolic_trace.Tracer,\n",
       " '_tracer_extras': {},\n",
       " 'meta': {}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bce46047-a98d-4c98-b156-ef9538774814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = torch.fx.Tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b47c757b-e4d1-4d40-a6ae-a1b2a850cdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = tracer.trace(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad1b7c5f-c2a6-45d5-b33f-d23d3784ca12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': ('', None),\n",
       " 'conv': ('conv', torch.nn.modules.conv.Conv2d),\n",
       " 'relu': ('relu', torch.nn.modules.activation.ReLU),\n",
       " 'sigmoid': ('', None),\n",
       " 'custom_act_act_myrelu': ('custom_act.act.myrelu',\n",
       "  torch.nn.modules.activation.ReLU),\n",
       " 'custom_act_act_myrelu_1': ('custom_act.act.myrelu',\n",
       "  torch.nn.modules.activation.ReLU),\n",
       " 'add': ('custom_act', __main__.MyAct),\n",
       " 'output': ('', None)}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer.node_name_to_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d40b3-4573-4705-a6b6-932e1bc830ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
