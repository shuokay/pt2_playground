{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0713940-1ad0-47eb-a6ce-7c9037277cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class <lambda>(torch.nn.Module):\n",
      "    def forward(self, arg0_1: f32[1, 1, 10, 10]):\n",
      "        # No stacktrace found for following nodes\n",
      "        _param_constant0 = self._param_constant0\n",
      "        _param_constant1 = self._param_constant1\n",
      "        convolution: f32[1, 3, 3, 3] = torch.ops.aten.convolution.default(arg0_1, _param_constant0, _param_constant1, [3, 3], [0, 0], [1, 1], False, [0, 0], 1);  arg0_1 = _param_constant0 = _param_constant1 = None\n",
      "        relu: f32[1, 3, 3, 3] = torch.ops.aten.relu.default(convolution);  convolution = None\n",
      "        detach: f32[1, 3, 3, 3] = torch.ops.aten.detach.default(relu)\n",
      "        sigmoid: f32[1, 3, 3, 3] = torch.ops.aten.sigmoid.default(relu);  relu = None\n",
      "        detach_1: f32[1, 3, 3, 3] = torch.ops.aten.detach.default(sigmoid)\n",
      "        relu_1: f32[1, 3, 3, 3] = torch.ops.aten.relu.default(sigmoid);  sigmoid = None\n",
      "        detach_2: f32[1, 3, 3, 3] = torch.ops.aten.detach.default(relu_1)\n",
      "        return relu_1\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class <lambda>(torch.nn.Module):\\n    def forward(self, arg0_1: f32[1, 1, 10, 10]):\\n        # No stacktrace found for following nodes\\n        _param_constant0 = self._param_constant0\\n        _param_constant1 = self._param_constant1\\n        convolution: f32[1, 3, 3, 3] = torch.ops.aten.convolution.default(arg0_1, _param_constant0, _param_constant1, [3, 3], [0, 0], [1, 1], False, [0, 0], 1);  arg0_1 = _param_constant0 = _param_constant1 = None\\n        relu: f32[1, 3, 3, 3] = torch.ops.aten.relu.default(convolution);  convolution = None\\n        detach: f32[1, 3, 3, 3] = torch.ops.aten.detach.default(relu)\\n        sigmoid: f32[1, 3, 3, 3] = torch.ops.aten.sigmoid.default(relu);  relu = None\\n        detach_1: f32[1, 3, 3, 3] = torch.ops.aten.detach.default(sigmoid)\\n        relu_1: f32[1, 3, 3, 3] = torch.ops.aten.relu.default(sigmoid);  sigmoid = None\\n        detach_2: f32[1, 3, 3, 3] = torch.ops.aten.detach.default(relu_1)\\n        return relu_1\\n        '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch._export import capture_pre_autograd_graph\n",
    "from torch.fx.experimental.proxy_tensor import make_fx\n",
    "\n",
    "\n",
    "class MyAct(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act = MyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(x)\n",
    "\n",
    "\n",
    "class MyReLU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.myrelu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.myrelu(x)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 3, 3, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.custom_act = MyAct()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.custom_act(x)\n",
    "        return x\n",
    "\n",
    "from torch import _guards\n",
    "from torch._subclasses import FakeTensorMode\n",
    "x  = torch.randn(1, 1, 10, 10)\n",
    "net = Net()\n",
    "y = net(x)\n",
    "# fake_mode = _guards.detect_fake_mode(x)\n",
    "# fake_tensor = fake_mode.from_tensor(x)\n",
    "\n",
    "\n",
    "with FakeTensorMode(allow_non_fake_inputs=True):\n",
    "    exported = make_fx(net, tracing_mode=\"real\")(x)\n",
    "exported.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf6fc57d-5a9a-41a2-ab18-e4942f2f19ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for n in exported.graph.nodes:\n",
    "    print(n.meta.get(\"nn_module_stack\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f75eed3-f630-43ba-b077-e0f5fdb970f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl'>\n"
     ]
    }
   ],
   "source": [
    "print(type(exported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc283ee1-b6fa-4f04-9fd8-d6fdfa98d602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
