{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d70a916-8530-4fdb-8d11-8b54f7227e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._export import capture_pre_autograd_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caac4691-048b-4ad7-875b-a968b4630cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, 3, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3704ddbc-6d46-4d0a-a196-e3a87c3cde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "x  = torch.randn(1, 1, 10, 10)\n",
    "exported = capture_pre_autograd_graph(net, (x, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97649c6-b55b-41ec-a5f9-47585ca2da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    arg0, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    _param_constant0 = self._param_constant0\n",
      "    _param_constant1 = self._param_constant1\n",
      "    conv2d_default = torch.ops.aten.conv2d.default(arg0, _param_constant0, _param_constant1, [3, 3]);  arg0 = _param_constant0 = _param_constant1 = None\n",
      "    relu_default = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\n",
      "    return pytree.tree_unflatten([relu_default], self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88374e1c-b74e-4830-97ad-a92c0a4338d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "{'is_torch_exported': True, 'val': FakeTensor(..., size=(1, 1, 10, 10))}\n",
      "-----------------\n",
      "{'from_node': [('l__self___conv', 'L__self___conv'),\n",
      "               ('_param_constant0', '_param_constant0')],\n",
      " 'is_torch_exported': True,\n",
      " 'nn_module_stack': {'L__self___conv': (\"L['self'].conv\",\n",
      "                                        <class 'torch.nn.modules.conv.Conv2d'>)},\n",
      " 'original_aten': <OpOverload(op='aten.conv2d', overload='default')>,\n",
      " 'seq_nr': 5,\n",
      " 'source_fn': ('l__self___conv', <class 'torch.nn.modules.conv.Conv2d'>),\n",
      " 'stack_trace': '  File \"/tmp/ipykernel_163612/1464477655.py\", line 10, in '\n",
      "                'forward\\n'\n",
      "                '    x = self.conv(x)\\n'}\n",
      "-----------------\n",
      "{'from_node': [('l__self___conv', 'L__self___conv'),\n",
      "               ('_param_constant1', '_param_constant1')],\n",
      " 'is_torch_exported': True,\n",
      " 'nn_module_stack': {'L__self___conv': (\"L['self'].conv\",\n",
      "                                        <class 'torch.nn.modules.conv.Conv2d'>)},\n",
      " 'original_aten': <OpOverload(op='aten.conv2d', overload='default')>,\n",
      " 'seq_nr': 5,\n",
      " 'source_fn': ('l__self___conv', <class 'torch.nn.modules.conv.Conv2d'>),\n",
      " 'stack_trace': '  File \"/tmp/ipykernel_163612/1464477655.py\", line 10, in '\n",
      "                'forward\\n'\n",
      "                '    x = self.conv(x)\\n'}\n",
      "-----------------\n",
      "{'from_node': [('l__self___conv', 'L__self___conv'),\n",
      "               ('conv2d', <OpOverload(op='aten.conv2d', overload='default')>)],\n",
      " 'is_torch_exported': True,\n",
      " 'nn_module_stack': {'L__self___conv': (\"L['self'].conv\",\n",
      "                                        <class 'torch.nn.modules.conv.Conv2d'>)},\n",
      " 'original_aten': <OpOverload(op='aten.conv2d', overload='default')>,\n",
      " 'seq_nr': 5,\n",
      " 'source_fn': ('l__self___conv', <class 'torch.nn.modules.conv.Conv2d'>),\n",
      " 'stack_trace': '  File \"/tmp/ipykernel_163612/1464477655.py\", line 10, in '\n",
      "                'forward\\n'\n",
      "                '    x = self.conv(x)\\n',\n",
      " 'val': FakeTensor(..., size=(1, 1, 3, 3))}\n",
      "-----------------\n",
      "{'from_node': [('l__self___relu', 'L__self___relu'),\n",
      "               ('relu', <OpOverload(op='aten.relu', overload='default')>)],\n",
      " 'is_torch_exported': True,\n",
      " 'nn_module_stack': {'L__self___relu': (\"L['self'].relu\",\n",
      "                                        <class 'torch.nn.modules.activation.ReLU'>)},\n",
      " 'original_aten': <OpOverload(op='aten.relu', overload='default')>,\n",
      " 'seq_nr': 5,\n",
      " 'source_fn': ('l__self___relu', <class 'torch.nn.modules.activation.ReLU'>),\n",
      " 'stack_trace': '  File \"/tmp/ipykernel_163612/1464477655.py\", line 11, in '\n",
      "                'forward\\n'\n",
      "                '    x = self.relu(x)\\n',\n",
      " 'val': FakeTensor(..., size=(1, 1, 3, 3))}\n",
      "-----------------\n",
      "{'is_torch_exported': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "for n in exported.graph.nodes:\n",
    "    print(\"-----------------\")\n",
    "    pprint(n.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d646a3-8cba-45b1-8a57-40bf7115b8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', GraphModule())]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(exported.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9268b2ff-a723-4a22-8fc2-861fc04d6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        arg0: f32[1, 1, 10, 10], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:10, code: x = self.conv(x)\n",
      "        _param_constant0 = self._param_constant0\n",
      "        _param_constant1 = self._param_constant1\n",
      "        conv2d_default: f32[1, 1, 3, 3] = torch.ops.aten.conv2d.default(arg0, _param_constant0, _param_constant1, [3, 3]);  arg0 = _param_constant0 = _param_constant1 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:11, code: x = self.relu(x)\n",
      "        relu_default: f32[1, 1, 3, 3] = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\n",
      "        return pytree.tree_unflatten([relu_default], self._out_spec)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, x):\\n        arg0: f32[1, 1, 10, 10], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\\n        # File: /tmp/ipykernel_163612/1464477655.py:10, code: x = self.conv(x)\\n        _param_constant0 = self._param_constant0\\n        _param_constant1 = self._param_constant1\\n        conv2d_default: f32[1, 1, 3, 3] = torch.ops.aten.conv2d.default(arg0, _param_constant0, _param_constant1, [3, 3]);  arg0 = _param_constant0 = _param_constant1 = None\\n        \\n        # File: /tmp/ipykernel_163612/1464477655.py:11, code: x = self.relu(x)\\n        relu_default: f32[1, 1, 3, 3] = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\\n        return pytree.tree_unflatten([relu_default], self._out_spec)\\n        '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee020a0-8312-4d90-bf1f-c2ae69e9f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.pt2e.utils import _get_node_name_to_scope\n",
    "x = _get_node_name_to_scope(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4f257c-d725-427c-b52d-36845d87d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arg0': ('', NoneType),\n",
       " '_param_constant0': ('conv', torch.nn.modules.conv.Conv2d),\n",
       " '_param_constant1': ('conv', torch.nn.modules.conv.Conv2d),\n",
       " 'conv2d_default': ('conv', torch.nn.modules.conv.Conv2d),\n",
       " 'relu_default': ('relu', torch.nn.modules.activation.ReLU),\n",
       " 'output': ('', NoneType)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04ad3c5e-e7d4-43a5-b3aa-9f68e074467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.quantize_pt2e import prepare_qat_pt2e\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
    "    get_symmetric_quantization_config,\n",
    "    XNNPACKQuantizer,\n",
    ")\n",
    "quantizer = XNNPACKQuantizer()\n",
    "quantizer.set_global(\n",
    "            get_symmetric_quantization_config(\n",
    "                is_per_channel=False, is_qat=True\n",
    "            )\n",
    "        )\n",
    "example_inputs = (torch.randn(1, 1, 10, 10),)\n",
    "model_pt2e = capture_pre_autograd_graph(\n",
    "            net,\n",
    "            example_inputs,\n",
    "        )\n",
    "model_pt2e = prepare_qat_pt2e(model_pt2e, quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3634311f-2d5a-40b9-a292-23067c7c50bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (activation_post_process_0): FusedMovingAvgObsFakeQuantize(\n",
       "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (activation_post_process_1): FusedMovingAvgObsFakeQuantize(\n",
       "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False\n",
       "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (activation_post_process_2): FusedMovingAvgObsFakeQuantize(\n",
       "    fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "    (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pt2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a7e37ce-536c-4254-bf33-35a18bc9a99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(3, 3))\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fa19812-6678-4f88-bcc2-68c7b27dfb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.4099, 0.0916],\n",
       "          [0.0756, 0.1704, 0.2025],\n",
       "          [0.0916, 0.1399, 0.0000]]]],\n",
       "       grad_fn=<FusedMovingAvgObsFqHelperBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pt2e(example_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "868727f0-8c75-49a7-9085-0f3a65ae7323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        arg0: f32[1, 1, 10, 10], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # No stacktrace found for following nodes\n",
      "        activation_post_process_0 = self.activation_post_process_0(arg0);  arg0 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:10, code: x = self.conv(x)\n",
      "        _param_constant0 = self._param_constant0\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        activation_post_process_1 = self.activation_post_process_1(_param_constant0);  _param_constant0 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:10, code: x = self.conv(x)\n",
      "        _param_constant1 = self._param_constant1\n",
      "        conv2d_default: f32[1, 1, 3, 3] = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, _param_constant1, [3, 3]);  activation_post_process_0 = activation_post_process_1 = _param_constant1 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:11, code: x = self.relu(x)\n",
      "        relu_default: f32[1, 1, 3, 3] = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        activation_post_process_2 = self.activation_post_process_2(relu_default);  relu_default = None\n",
      "        return pytree.tree_unflatten([activation_post_process_2], self._out_spec)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        arg0: f32[1, 1, 10, 10], = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # No stacktrace found for following nodes\n",
      "        activation_post_process_0 = self.activation_post_process_0(arg0);  arg0 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:10, code: x = self.conv(x)\n",
      "        _param_constant0 = self._param_constant0\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        activation_post_process_1 = self.activation_post_process_1(_param_constant0);  _param_constant0 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:10, code: x = self.conv(x)\n",
      "        _param_constant1 = self._param_constant1\n",
      "        conv2d_default: f32[1, 1, 3, 3] = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, _param_constant1, [3, 3]);  activation_post_process_0 = activation_post_process_1 = _param_constant1 = None\n",
      "        \n",
      "        # File: /tmp/ipykernel_163612/1464477655.py:11, code: x = self.relu(x)\n",
      "        relu_default: f32[1, 1, 3, 3] = torch.ops.aten.relu.default(conv2d_default);  conv2d_default = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        activation_post_process_2 = self.activation_post_process_2(relu_default);  relu_default = None\n",
      "        return pytree.tree_unflatten([activation_post_process_2], self._out_spec)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(model_pt2e.print_readable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff37b4c-11cf-45ee-84fb-1831d457a9df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GraphModule' object has no attribute 'conv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_pt2e\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch210/lib/python3.8/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphModule' object has no attribute 'conv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bc092-999d-4572-9969-6682c0776cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
