{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717894f8-4beb-46af-b8aa-db3ff39d82ee",
   "metadata": {},
   "source": [
    "# 结论 2023-12-07\n",
    "和 dynamo export 一致\n",
    "\n",
    "1. 不支持 Tensor 作为控制条件\n",
    "2. 只支持静态控制场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa794a4b-b06b-42c6-94c9-fb8ee516d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be65744-f922-4660-b485-ffe6b5ee1f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, arg0_1: f32[3]):\n",
      "            # \n",
      "            sigmoid: f32[3] = torch.ops.aten.sigmoid.default(arg0_1);  arg0_1 = None\n",
      "            return (sigmoid,)\n",
      "            \n",
      "Graph Signature: ExportGraphSignature(parameters=[], buffers=[], user_inputs=['arg0_1'], user_outputs=['sigmoid'], inputs_to_parameters={}, inputs_to_buffers={}, buffers_to_mutate={}, backward_signature=None, assertion_dep_token=None)\n",
      "Symbol to range: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fn(x):\n",
    "    if x.sum() > 0:\n",
    "        return torch.relu(x)\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "flag = torch.randn(1) > 0.5 # failed, Dynamic control flow is not supported at the moment\n",
    "flag = torch.randn(1).item() > 0.5\n",
    "\n",
    "def static_flag_fn(x):\n",
    "    if flag:\n",
    "        return torch.relu(x)\n",
    "    return torch.sigmoid(x)\n",
    "\n",
    "x = torch.randn(3)\n",
    "out = torch.export.export(static_flag_fn, (x,))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40c1736-1604-49c2-91df-5a58ab46be58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconstraints\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstraint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExportedProgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       ":func:`export` takes an arbitrary Python callable (an nn.Module, a function or\n",
       "a method) and produces a traced graph representing only the Tensor\n",
       "computation of the function in an Ahead-of-Time (AOT) fashion, which can\n",
       "subsequently be executed with different outputs or serialized.  The traced\n",
       "graph (1) produces a normalized operator set consisting only of functional\n",
       "`Core ATen Operator Set <https://pytorch.org/docs/stable/ir.html>`_\n",
       "and user specified custom operators, (2) has eliminated all Python control\n",
       "flow and data structures (except for certain\n",
       "conditions), and (3) has the set of shape constraints needed to show that\n",
       "this normalization and control flow elimination is sound for a future\n",
       "input.\n",
       "\n",
       "**Soundness Guarantee**\n",
       "\n",
       "While tracing, :func:`export()` takes note of shape-related assumptions\n",
       "made by the user program and the underlying PyTorch operator kernels.\n",
       "The output :class:`ExportedProgram` is considered valid only when these\n",
       "assumptions hold true.\n",
       "\n",
       "There are 2 types of assumptions made during tracing\n",
       "\n",
       "- Shapes (not values) of input tensors.\n",
       "- Ranges (lower and upper bound) of values extracted from intermediate tensors via ``.item()`` or direct indexing.\n",
       "\n",
       "\n",
       "All assumptions must be validated at graph capture time for :func:`export`\n",
       "to succeed. Specifically:\n",
       "\n",
       "- Assumptions on static shapes of input tensors are automatically validated without additional effort.\n",
       "- Assumptions on dynamic shape of input tensors require explicit `Input Constraint`\n",
       "  constructed with :func:`dynamic_dim` APIs\n",
       "- Assumptions on range of intermediate values require explicit `Inline Constraint`,\n",
       "  constructed use :func:`constrain_as_size` and :func:`constraint_as_value` APIs.\n",
       "\n",
       "If any assumption can not be validated, a fatal error will be raised. When that happens,\n",
       "the error message will include suggested code needed to construct necessary\n",
       "constraints to validate the assumptions, for example :func:`export` would suggest\n",
       "following code for input constraints::\n",
       "\n",
       "    def specify_constraints(x):\n",
       "        return [\n",
       "            # x:\n",
       "            dynamic_dim(x, 0) <= 5,\n",
       "        ]\n",
       "\n",
       "This example means the program requires the dim 0 of input ``x`` to be less\n",
       "than or equal to 5 to be valid. You can inspect the constraints needed and\n",
       "then copy this exact function into your code to generated needed\n",
       "constraints to be passed into ``constraints`` argument.\n",
       "\n",
       "Args:\n",
       "    f: The callable to trace.\n",
       "\n",
       "    args: Example positional inputs.\n",
       "\n",
       "    kwargs: Optional example keyword inputs.\n",
       "\n",
       "    constraints: An optional list of constraints on the dynamic arguments\n",
       "     that specify their possible range of shapes. By default, shapes of\n",
       "     input torch.Tensors are assumed to be static. If an input torch.Tensor\n",
       "     is expected to have dynamic shapes, please use :func:`dynamic_dim`\n",
       "     to define :class:`Constraint` objects that specify the dynamics and the possible\n",
       "     range of shapes. See :func:`dynamic_dim` docstring for examples on\n",
       "     how to use it.\n",
       "\n",
       "Returns:\n",
       "    An :class:`ExportedProgram` containing the traced callable.\n",
       "\n",
       "**Acceptable input/output types**\n",
       "\n",
       "Acceptable types of inputs (for ``args`` and ``kwargs``) and outputs include:\n",
       "\n",
       "- Primitive types, i.e. ``torch.Tensor``, ``int``, ``float``, ``bool`` and ``str``.\n",
       "- (Nested) Data structures comprising of ``dict``, ``list``, ``tuple``, ``namedtuple`` and\n",
       "  ``OrderedDict`` containing all above types.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/torch210/lib/python3.8/site-packages/torch/export/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.export.export(fn, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6a088-b602-46c4-94b5-fb67c22c8908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
